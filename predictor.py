#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
3D UNet é æ¸¬è…³æœ¬
è¼‰å…¥è¨“ç·´å¥½çš„æ¨¡å‹æ¬Šé‡ï¼Œå°æŒ‡å®šè³‡æ–™å¤¾ä¸­çš„ nii.gz or nii æª”æ¡ˆé€²è¡Œé æ¸¬
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import nibabel as nib
from pathlib import Path
import sys
import argparse
import warnings
import json
from typing import List, Tuple, Optional, Dict
import time
from tqdm import tqdm
import os

# å¿½ç•¥è­¦å‘Š
warnings.filterwarnings('ignore')

from src.network_architecture.net_module import *
from src.network_architecture.unet3d import UNet3D
from trainer import EnhancedUNet3DTrainer

class UNet3DPredictor:
    """3D UNet é æ¸¬å™¨é¡åˆ¥"""
    
    def __init__(self, model_path: str, device: str = 'auto'):
        """
        åˆå§‹åŒ–é æ¸¬å™¨
        
        Args:
            model_path: æ¨¡å‹æ¬Šé‡æª”æ¡ˆè·¯å¾‘ (.pth)
            device: è¨ˆç®—è¨­å‚™ ('auto', 'cpu', 'cuda')
        """
        self.model_path = Path(model_path)
        if not self.model_path.exists():
            raise FileNotFoundError(f"æ¨¡å‹æª”æ¡ˆä¸å­˜åœ¨: {model_path}")
        
        # è¨­ç½®è¨­å‚™
        if device == 'auto':
            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        else:
            self.device = torch.device(device)
        
        print(f"ä½¿ç”¨è¨­å‚™: {self.device}")
        if self.device.type == 'cuda':
            print(f"GPU åç¨±: {torch.cuda.get_device_name(self.device)}")
            print(f"GPU è¨˜æ†¶é«”: {torch.cuda.get_device_properties(self.device).total_memory / 1024**3:.1f} GB")
        
        # è¼‰å…¥æ¨¡å‹
        self.model = None
        self.model_config = None
        self._load_model()
        
        print("æ¨¡å‹è¼‰å…¥å®Œæˆï¼Œæº–å‚™é€²è¡Œé æ¸¬")
    
    def safe_torch_load(self, path):
        """å®‰å…¨çš„ torch.load å‡½æ•¸ï¼Œå…¼å®¹ PyTorch 2.6+"""
        try:
            return torch.load(path, map_location=self.device, weights_only=False)
        except Exception as e1:
            try:
                print(f"ä½¿ç”¨ weights_only=False è¼‰å…¥å¤±æ•—ï¼Œå˜—è©¦ weights_only=True")
                return torch.load(path, map_location=self.device, weights_only=True)
            except Exception as e2:
                print(f"æ­£åœ¨è¨­ç½®å®‰å…¨å…¨åŸŸè®Šæ•¸ä¸¦é‡æ–°è¼‰å…¥...")
                torch.serialization.add_safe_globals([
                    'numpy._core.multiarray.scalar',
                    'numpy.core.multiarray.scalar',
                    'numpy.dtype',
                    'numpy.ndarray',
                    'collections.OrderedDict'
                ])
                return torch.load(path, map_location=self.device, weights_only=True)
    
    def _clean_state_dict(self, state_dict):
        """æ¸…ç†ç‹€æ…‹å­—å…¸ï¼Œç§»é™¤ thop æ·»åŠ çš„é¡å¤–éµå€¼"""
        # éœ€è¦ç§»é™¤çš„éµå€¼æ¨¡å¼
        keys_to_remove = []
        for key in state_dict.keys():
            if 'total_ops' in key or 'total_params' in key:
                keys_to_remove.append(key)
        
        # ç§»é™¤é€™äº›éµå€¼
        for key in keys_to_remove:
            del state_dict[key]
            
        return state_dict
    
    def _load_model(self):
        """è¼‰å…¥æ¨¡å‹æ¬Šé‡"""
        print(f"è¼‰å…¥æ¨¡å‹æ¬Šé‡: {self.model_path}")
        
        try:
            checkpoint = self.safe_torch_load(self.model_path)
            
            # æå–æ¨¡å‹é…ç½®
            if 'model_config' in checkpoint:
                self.model_config = checkpoint['model_config']
                print(f"è¼‰å…¥æ¨¡å‹é…ç½®: {self.model_config}")
            else:
                # ä½¿ç”¨é è¨­é…ç½®
                self.model_config = {
                    'n_channels': 1,
                    'n_classes': 2,
                    'base_channels': 64,
                    'num_groups': 8,
                    'bilinear': False
                }
                print("ä½¿ç”¨é è¨­æ¨¡å‹é…ç½®")
            
            # å»ºç«‹æ¨¡å‹
            self.model = UNet3D(
                n_channels=self.model_config.get('n_channels', 1),
                n_classes=self.model_config.get('n_classes', 2),
                base_channels=self.model_config.get('base_channels', 64),
                num_groups=self.model_config.get('num_groups', 8),
                bilinear=self.model_config.get('bilinear', False)
            ).to(self.device)
            
            # æ¸…ç†ç‹€æ…‹å­—å…¸ä¸¦è¼‰å…¥æ¬Šé‡
            model_state_dict = checkpoint['model_state_dict']
            cleaned_state_dict = self._clean_state_dict(model_state_dict)
            self.model.load_state_dict(cleaned_state_dict)
            self.model.eval()
            
            # é¡¯ç¤ºæ¨¡å‹è³‡è¨Š
            total_params, trainable_params = self.model.get_model_size()
            print(f"æ¨¡å‹åƒæ•¸: {total_params:,} ({trainable_params:,} å¯è¨“ç·´)")
            
            # é¡¯ç¤ºè¨“ç·´è³‡è¨Š
            if 'epoch' in checkpoint:
                print(f"æ¨¡å‹è¨“ç·´åˆ°ç¬¬ {checkpoint['epoch']} epoch")
            if 'best_val_dice' in checkpoint:
                print(f"æœ€ä½³é©—è­‰ Dice: {checkpoint['best_val_dice']:.4f}")
                
        except Exception as e:
            print(f"è¼‰å…¥æ¨¡å‹æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            raise
    
    def load_nii_image(self, file_path: Path) -> np.ndarray:
        """è¼‰å…¥ NII.GZ æª”æ¡ˆ"""
        try:
            nii_img = nib.load(str(file_path))
            img_data = nii_img.get_fdata()
            img_data = np.array(img_data, dtype=np.float32)
            
            # è™•ç†ä¸åŒç¶­åº¦çš„å½±åƒ
            if img_data.ndim == 4:
                # ğŸ”§ è‹¥æ˜¯4Då½±åƒ (X, Y, Z, T)ï¼Œåªå–ç¬¬0å€‹æ™‚é–“é»
                print(f"âš ï¸ åµæ¸¬åˆ°4Då½±åƒ {img_data.shape}ï¼Œè‡ªå‹•å–æœ€å¾Œä¸€ç¶­çš„ index=0")
                img_data = img_data[..., 0]
            elif img_data.ndim == 3:
                # âœ… 3Då½±åƒï¼Œç¶­æŒåŸæ¨£
                print(f"âœ… åµæ¸¬åˆ°3Då½±åƒ {img_data.shape}")
            elif img_data.ndim == 2:
                # ğŸ”§ è‹¥æ˜¯2Då½±åƒï¼Œæ·»åŠ æ·±åº¦ç¶­åº¦ (H, W) -> (1, H, W)
                print(f"âš ï¸ åµæ¸¬åˆ°2Då½±åƒ {img_data.shape}ï¼Œæ·»åŠ æ·±åº¦ç¶­åº¦")
                img_data = img_data[np.newaxis, ...]
            elif img_data.ndim > 4:
                # ğŸš¨ è¶…é4Dçš„å½±åƒï¼Œå–å‰3å€‹ç¶­åº¦
                print(f"âš ï¸ åµæ¸¬åˆ°{img_data.ndim}Då½±åƒ {img_data.shape}ï¼Œåªå–å‰3å€‹ç¶­åº¦")
                img_data = img_data[..., 0, 0] if img_data.ndim == 5 else img_data
                # å¦‚æœé‚„æ˜¯è¶…é3Dï¼Œç¹¼çºŒé™ç¶­ç›´åˆ°3D
                while img_data.ndim > 3:
                    img_data = img_data[..., 0]
            else:
                raise ValueError(f"ä¸æ”¯æ´çš„å½±åƒç¶­åº¦: {img_data.ndim}D")
            
            # ç¢ºä¿æœ€çµ‚çµæœæ˜¯3D
            if img_data.ndim != 3:
                raise ValueError(f"è™•ç†å¾Œçš„å½±åƒç¶­åº¦ä¸æ­£ç¢º: {img_data.ndim}Dï¼ŒæœŸæœ›3D")
                
            print(f"ğŸ“Š æœ€çµ‚å½±åƒå½¢ç‹€: {img_data.shape}")
            return img_data
            
        except Exception as e:
            print(f"è®€å–æª”æ¡ˆ {file_path} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            raise
    
    def normalize_image(self, image: np.ndarray) -> np.ndarray:
        """å½±åƒæ¨™æº–åŒ–"""
        # ç§»é™¤ç•°å¸¸å€¼
        p1, p99 = np.percentile(image, (1, 99))
        image = np.clip(image, p1, p99)
        
        # Z-score æ¨™æº–åŒ–
        mean = np.mean(image)
        std = np.std(image)
        if std > 0:
            image = (image - mean) / std
        
        return image
    
    def resize_volume(self, volume: np.ndarray, target_size: Tuple[int, int, int]) -> np.ndarray:
        """èª¿æ•´ 3D é«”ç©å¤§å°"""
        if target_size is None:
            return volume
            
        from scipy.ndimage import zoom
        
        current_size = volume.shape
        zoom_factors = [t/c for t, c in zip(target_size, current_size)]
        resized = zoom(volume, zoom_factors, order=1)  # ç·šæ€§æ’å€¼
        
        return resized
    
    def preprocess_image(self, image: np.ndarray, target_size: Optional[Tuple[int, int, int]] = None) -> torch.Tensor:
        """é è™•ç†å–®å¼µå½±åƒ"""
        # èª¿æ•´å¤§å°
        if target_size is not None:
            image = self.resize_volume(image, target_size)
        
        # æ¨™æº–åŒ–
        image = self.normalize_image(image)
        
        # æ·»åŠ é€šé“ç¶­åº¦å’Œæ‰¹æ¬¡ç¶­åº¦ï¼š[D, H, W] -> [1, 1, D, H, W]
        image = image[np.newaxis, np.newaxis, ...]
        
        # è½‰æ›ç‚º tensor
        image = torch.from_numpy(image).float().to(self.device)
        
        return image
    
    def postprocess_prediction(self, prediction: torch.Tensor, original_size: Tuple[int, int, int]) -> np.ndarray:
        """å¾Œè™•ç†é æ¸¬çµæœ"""
        # ç§»é™¤æ‰¹æ¬¡ç¶­åº¦å’Œé€šé“ç¶­åº¦
        if len(prediction.shape) == 5:  # [1, C, D, H, W]
            prediction = prediction.squeeze(0)
        
        # å¦‚æœæ˜¯å¤šé¡åˆ¥ï¼Œå–æœ€å¤§æ¦‚ç‡çš„é¡åˆ¥
        if prediction.shape[0] > 1:
            prediction = torch.argmax(prediction, dim=0)
        else:
            # äºŒåˆ†é¡æƒ…æ³
            prediction = torch.sigmoid(prediction.squeeze(0))
            prediction = (prediction > 0.5).float()
        
        # è½‰ç‚º numpy
        prediction = prediction.cpu().numpy().astype(np.uint8)
        
        # èª¿æ•´å›åŸå§‹å¤§å°
        if prediction.shape != original_size:
            from scipy.ndimage import zoom
            zoom_factors = [o/p for o, p in zip(original_size, prediction.shape)]
            prediction = zoom(prediction, zoom_factors, order=0)  # æœ€è¿‘é„°æ’å€¼
            prediction = prediction.astype(np.uint8)
        
        return prediction
    
    def predict_single_image(self, image_path: Path, target_size: Optional[Tuple[int, int, int]] = None) -> Tuple[np.ndarray, Dict]:
        """é æ¸¬å–®å¼µå½±åƒ"""
        # è¼‰å…¥åŸå§‹å½±åƒ
        original_image = self.load_nii_image(image_path)
        original_size = original_image.shape
        
        # é è™•ç†
        input_tensor = self.preprocess_image(original_image, target_size)
        
        # é æ¸¬
        with torch.no_grad():
            start_time = time.time()
            prediction = self.model(input_tensor)
            inference_time = time.time() - start_time
        
        # å¾Œè™•ç†
        prediction_mask = self.postprocess_prediction(prediction, original_size)
        
        # è¨ˆç®—çµ±è¨ˆè³‡è¨Š
        stats = {
            'original_size': original_size,
            'input_size': input_tensor.shape[2:],  # å»æ‰æ‰¹æ¬¡å’Œé€šé“ç¶­åº¦
            'inference_time': inference_time,
            'foreground_pixels': int(np.sum(prediction_mask > 0)),
            'total_pixels': int(prediction_mask.size),
            'foreground_ratio': float(np.sum(prediction_mask > 0) / prediction_mask.size)
        }
        
        return prediction_mask, stats
    
    def save_prediction(self, prediction: np.ndarray, original_nii_path: Path, output_path: Path):
        """ä¿å­˜é æ¸¬çµæœç‚º NII.GZ æ ¼å¼"""
        try:
            # è¼‰å…¥åŸå§‹æª”æ¡ˆä»¥ä¿æŒç›¸åŒçš„ä»¿å°„è®Šæ›å’Œé ­éƒ¨è³‡è¨Š
            original_nii = nib.load(str(original_nii_path))
            
            # å‰µå»ºæ–°çš„ NII å½±åƒ
            prediction_nii = nib.Nifti1Image(
                prediction, 
                original_nii.affine, 
                original_nii.header
            )
            
            # æ›´æ–°è³‡æ–™é¡å‹
            prediction_nii.set_data_dtype(np.uint8)
            
            # ä¿å­˜
            nib.save(prediction_nii, str(output_path))
            print(f"é æ¸¬çµæœå·²ä¿å­˜: {output_path}")
            
        except Exception as e:
            print(f"ä¿å­˜é æ¸¬çµæœæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            raise
    
    def predict_folder(self, 
                      input_folder: str, 
                      output_folder: str, 
                      target_size: Optional[Tuple[int, int, int]] = None,
                      file_pattern: str = "*.nii.gz",
                      save_stats: bool = True) -> Dict:
        """
        é æ¸¬æ•´å€‹è³‡æ–™å¤¾ä¸­çš„æ‰€æœ‰ NII.GZ æª”æ¡ˆ
        
        Args:
            input_folder: è¼¸å…¥è³‡æ–™å¤¾è·¯å¾‘
            output_folder: è¼¸å‡ºè³‡æ–™å¤¾è·¯å¾‘
            target_size: ç›®æ¨™å°ºå¯¸ (D, H, W)ï¼ŒNone è¡¨ç¤ºä¿æŒåŸå§‹å¤§å°
            file_pattern: æª”æ¡ˆæ¨¡å¼
            save_stats: æ˜¯å¦ä¿å­˜çµ±è¨ˆè³‡è¨Š
        
        Returns:
            dict: é æ¸¬çµ±è¨ˆè³‡è¨Š
        """
        input_path = Path(input_folder)
        output_path = Path(output_folder)
        
        # æª¢æŸ¥è¼¸å…¥è³‡æ–™å¤¾
        if not input_path.exists():
            raise FileNotFoundError(f"è¼¸å…¥è³‡æ–™å¤¾ä¸å­˜åœ¨: {input_path}")
        
        # å‰µå»ºè¼¸å‡ºè³‡æ–™å¤¾
        output_path.mkdir(parents=True, exist_ok=True)
        
        # å°‹æ‰¾æ‰€æœ‰ NII.GZ æª”æ¡ˆ
        nii_files = list(input_path.glob(file_pattern))
        if not nii_files:
            raise ValueError(f"åœ¨ {input_path} ä¸­æ‰¾ä¸åˆ°ç¬¦åˆ {file_pattern} çš„æª”æ¡ˆ")
        
        print(f"æ‰¾åˆ° {len(nii_files)} å€‹æª”æ¡ˆéœ€è¦é æ¸¬")
        print(f"è¼¸å‡ºè³‡æ–™å¤¾: {output_path}")
        if target_size:
            print(f"ç›®æ¨™å°ºå¯¸: {target_size}")
        
        # é æ¸¬çµ±è¨ˆ
        all_stats = {}
        total_time = 0
        successful_predictions = 0
        
        # ä½¿ç”¨é€²åº¦æ¢
        for nii_file in tqdm(nii_files, desc="é æ¸¬é€²åº¦"):
            try:
                # é æ¸¬
                prediction, stats = self.predict_single_image(nii_file, target_size)
                
                # ç”Ÿæˆè¼¸å‡ºæª”æ¡ˆåç¨±
                output_file = output_path / f"pred_{nii_file.name}"
                
                # ä¿å­˜é æ¸¬çµæœ
                self.save_prediction(prediction, nii_file, output_file)
                
                # è¨˜éŒ„çµ±è¨ˆ
                stats['input_file'] = str(nii_file)
                stats['output_file'] = str(output_file)
                all_stats[nii_file.name] = stats
                
                total_time += stats['inference_time']
                successful_predictions += 1
                
                # é¡¯ç¤ºç°¡è¦è³‡è¨Š
                tqdm.write(f"âœ… {nii_file.name}: {stats['foreground_ratio']:.1%} å‰æ™¯åƒç´ , "
                          f"{stats['inference_time']:.2f}s")
                
            except Exception as e:
                tqdm.write(f"âŒ é æ¸¬ {nii_file.name} å¤±æ•—: {e}")
                continue
        
        # è¨ˆç®—ç¸½é«”çµ±è¨ˆ
        summary_stats = {
            'total_files': len(nii_files),
            'successful_predictions': successful_predictions,
            'failed_predictions': len(nii_files) - successful_predictions,
            'total_inference_time': total_time,
            'average_inference_time': total_time / successful_predictions if successful_predictions > 0 else 0,
            'model_config': self.model_config,
            'target_size': target_size
        }
        
        print(f"\né æ¸¬å®Œæˆ!")
        print(f"æˆåŠŸ: {successful_predictions}/{len(nii_files)}")
        print(f"ç¸½æ¨ç†æ™‚é–“: {total_time:.2f} ç§’")
        print(f"å¹³å‡æ¨ç†æ™‚é–“: {summary_stats['average_inference_time']:.2f} ç§’/æª”æ¡ˆ")
        
        # ä¿å­˜çµ±è¨ˆè³‡è¨Š
        if save_stats:
            stats_file = output_path / 'prediction_stats.json'
            full_stats = {
                'summary': summary_stats,
                'individual_files': all_stats
            }
            
            with open(stats_file, 'w', encoding='utf-8') as f:
                json.dump(full_stats, f, ensure_ascii=False, indent=2)
            
            print(f"çµ±è¨ˆè³‡è¨Šå·²ä¿å­˜: {stats_file}")
        
        return summary_stats

def main():
    """ä¸»å‡½æ•¸"""
    parser = argparse.ArgumentParser(
        description='3D UNet é æ¸¬è…³æœ¬',
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )
    
    parser.add_argument('model_path', type=str, help='æ¨¡å‹æ¬Šé‡æª”æ¡ˆè·¯å¾‘ (.pth)')
    parser.add_argument('input_folder', type=str, help='è¼¸å…¥è³‡æ–™å¤¾è·¯å¾‘')
    parser.add_argument('output_folder', type=str, help='è¼¸å‡ºè³‡æ–™å¤¾è·¯å¾‘')
    
    parser.add_argument('--target_size', type=int, nargs=3, metavar=('D', 'H', 'W'),
                       help='ç›®æ¨™å°ºå¯¸ (æ·±åº¦ é«˜åº¦ å¯¬åº¦)ï¼Œä¾‹å¦‚: --target_size 64 64 64')
    parser.add_argument('--device', type=str, default='auto', 
                       choices=['auto', 'cpu', 'cuda'], help='è¨ˆç®—è¨­å‚™')
    parser.add_argument('--pattern', type=str, default='*.nii.gz',
                       help='æª”æ¡ˆæ¨¡å¼')
    parser.add_argument('--no_stats', action='store_true',
                       help='ä¸ä¿å­˜çµ±è¨ˆè³‡è¨Š')
    
    args = parser.parse_args()
    
    print("ğŸ§  3D UNet é æ¸¬ç³»çµ±")
    print("=" * 50)
    
    try:
        # å‰µå»ºé æ¸¬å™¨
        predictor = UNet3DPredictor(args.model_path, args.device)
        
        # è½‰æ›ç›®æ¨™å°ºå¯¸
        target_size = tuple(args.target_size) if args.target_size else None
        
        # åŸ·è¡Œé æ¸¬
        stats = predictor.predict_folder(
            input_folder=args.input_folder,
            output_folder=args.output_folder,
            target_size=target_size,
            file_pattern=args.pattern,
            save_stats=not args.no_stats
        )
        
        print("\nğŸ‰ æ‰€æœ‰é æ¸¬å®Œæˆ!")
        
    except KeyboardInterrupt:
        print("\nâ¹ï¸ é æ¸¬è¢«ç”¨æˆ¶ä¸­æ–·")
    except Exception as e:
        print(f"\nâŒ é æ¸¬éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()

def predict_single_example():
    """å–®æª”æ¡ˆé æ¸¬ç¯„ä¾‹"""
    print("å–®æª”æ¡ˆé æ¸¬ç¯„ä¾‹:")
    
    # åƒæ•¸è¨­å®š
    model_path = r"model.pth"
    image_path = r"image.nii.gz"
    output_path = r"predictions\pred_image.nii.gz"
    target_size = (64, 64, 64)  # æˆ– None ä¿æŒåŸå§‹å¤§å°
    
    try:
        # å‰µå»ºé æ¸¬å™¨
        predictor = UNet3DPredictor(model_path, device='auto')
        
        # é æ¸¬å–®å¼µå½±åƒ
        prediction, stats = predictor.predict_single_image(
            Path(image_path), 
            target_size
        )
        
        # ä¿å­˜çµæœ
        Path(output_path).parent.mkdir(parents=True, exist_ok=True)
        predictor.save_prediction(prediction, Path(image_path), Path(output_path))
        
        print(f"é æ¸¬çµ±è¨ˆ: {stats}")
        print("é æ¸¬å®Œæˆ!")
        
    except Exception as e:
        print(f"é æ¸¬å¤±æ•—: {e}")

if __name__ == "__main__":
    main()