#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¨ç†æ¸¬è©¦è…³æœ¬ - ä½¿ç”¨å„ªåŒ–ç‰ˆæœ¬ï¼ˆä¿®å¾© Windows è·¯å¾‘å•é¡Œï¼‰
âœ… ç›´æ¥ä½¿ç”¨è¨“ç·´æ™‚çš„æ•¸æ“šè®€å–å’Œé è™•ç†æ–¹å¼ï¼ˆnnUNet é¢¨æ ¼ï¼‰
âœ… æ–°å¢åŠŸèƒ½ï¼šä¿å­˜ Dice åˆ†æ•¸åˆ° txtã€ç”Ÿæˆå¯è¦–åŒ–çµæœ
åªéœ€è¦å¡«å¯«é…ç½®åƒæ•¸ï¼Œå…¶ä»–éƒ½æ˜¯è‡ªå‹•åŒ–çš„
"""

import torch
from pathlib import Path
import numpy as np
from datetime import datetime
import json
try:
    import nibabel as nib
    from scipy import ndimage
    import matplotlib.pyplot as plt
    import matplotlib.patches as mpatches
    VISUALIZATION_AVAILABLE = True
except ImportError:
    VISUALIZATION_AVAILABLE = False
    print("âš ï¸  è­¦å‘Šï¼šç¼ºå°‘å¯è¦–åŒ–ä¾è³´ (nibabel, scipy, matplotlib)ï¼Œå°‡ç„¡æ³•ç”Ÿæˆåœ–ç‰‡")

from test_inference import ModelInference  # å„ªå…ˆä½¿ç”¨å„ªåŒ–ç‰ˆæœ¬


# ========================================
# â¬‡ï¸  å¡«å¯«ä½ çš„é…ç½®ï¼ˆå¿…éœ€ä¿®æ”¹ï¼‰
# ========================================

# 1ï¸âƒ£ æ¨¡å‹è·¯å¾‘ï¼ˆå¿…éœ€ï¼‰
# âœ… ä½¿ç”¨æ­£æ–œæ  / æˆ–é›™åæ–œæ  \\ ä¾†é¿å…è½‰ç¾©å•é¡Œ
MODEL_PATH = r"best_val_dice_model.pth"        #è®€å–è¨“ç·´å¥½çš„æ¬Šé‡

# 2ï¸âƒ£ æ¸¬è©¦æ•¸æ“šè·¯å¾‘ï¼ˆå¿…éœ€ï¼‰
IMAGES_DIR = r"D:/UNet/dataset/test/images"              # æ¸¬è©¦å½±åƒæ–‡ä»¶å¤¾
MASKS_DIR = r"D:/UNet/dataset/test/labels"               # æ¸¬è©¦é®ç½©æ–‡ä»¶å¤¾ï¼ˆå¯é¸ï¼‰

# 3ï¸âƒ£ æ¨¡å‹é…ç½®ï¼ˆå¿…éœ€ - æ ¹æ“šä½ çš„è¨“ç·´é…ç½®å¡«å¯«ï¼‰
MODEL_CONFIG = {
    'n_channels': 1,           # è¼¸å…¥é€šé“æ•¸ï¼ˆç°éš=1, RGB=3ï¼‰
    'n_classes': 2,            # è¼¸å‡ºé¡åˆ¥æ•¸ï¼ˆäºŒåˆ†é¡=2ï¼‰
    'base_channels': 32,       # åŸºç¤é€šé“æ•¸
    'num_groups': 8,           # GroupNorm çµ„æ•¸
    'bilinear': False          # æ˜¯å¦ä½¿ç”¨é›™ç·šæ€§ä¸Šæ¡æ¨£
}

# 4ï¸âƒ£ å…¶ä»–åƒæ•¸ï¼ˆå¯é¸ï¼‰
TARGET_SIZE = (64, 64, 64)    # å½±åƒå°ºå¯¸ (æ·±åº¦, é«˜åº¦, å¯¬åº¦) - å¿…é ˆèˆ‡è¨“ç·´æ™‚ç›¸åŒ
DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'  # è‡ªå‹•é¸æ“‡è¨­å‚™
OUTPUT_DIR = r"./result"  # çµæœä¿å­˜ç›®éŒ„
SAVE_RESULTS = True           # æ˜¯å¦ä¿å­˜çµæœ

# 5ï¸âƒ£ å¯è¦–åŒ–åƒæ•¸ï¼ˆæ–°å¢ï¼‰
GENERATE_VISUALIZATIONS = True   # æ˜¯å¦ç”Ÿæˆå¯è¦–åŒ–åœ–ç‰‡
VIZ_SLICE_MODE = 'max'        # 'middle'=ä¸­é–“åˆ‡ç‰‡, 'max'=æœ€å¤§æ¿€æ´»åˆ‡ç‰‡, 'all'=æ‰€æœ‰åˆ‡ç‰‡
VIZ_DPI = 300                    # åœ–ç‰‡è§£æåº¦ (DPI)
VIZ_CMAP = 'viridis'                 # é æ¸¬é®ç½©è‰²åœ–ï¼š'hot', 'jet', 'viridis', 'gray', 'bone' ç­‰

# 6ï¸âƒ£ nnUNet é¢¨æ ¼çš„ resampling åƒæ•¸ï¼ˆå¯é¸ï¼‰
SPACING = None                # åŸå§‹è³‡æ–™çš„ spacing (z, y, x)
FORCE_SEPARATE_Z = None       # å¼·åˆ¶æ˜¯å¦åˆ†é›¢ z è»¸è™•ç†

# ========================================


class VisualizationHelper:
    """å¯è¦–åŒ–è¼”åŠ©é¡"""
    
    @staticmethod
    def load_nii_image(file_path):
        """è¼‰å…¥ NII å½±åƒ"""
        if not VISUALIZATION_AVAILABLE:
            return None
        try:
            nii_img = nib.load(str(file_path))
            return nii_img.get_fdata()
        except Exception as e:
            print(f"   âš ï¸  ç„¡æ³•è¼‰å…¥åŸå§‹ NII å½±åƒ: {e}")
            return None
    
    @staticmethod
    def find_best_slice(mask, direction='z'):
        """æ‰¾åˆ°æœ€ä½³çš„å±•ç¤ºåˆ‡ç‰‡ï¼ˆå«æœ‰æœ€å¤šé æ¸¬çš„åˆ‡ç‰‡ï¼‰"""
        if mask.ndim != 3:
            return mask.shape[0] // 2
        
        if direction == 'z':
            slice_sums = np.sum(mask, axis=(1, 2))
        elif direction == 'y':
            slice_sums = np.sum(mask, axis=(0, 2))
        else:  # x
            slice_sums = np.sum(mask, axis=(0, 1))
        
        return np.argmax(slice_sums) if np.max(slice_sums) > 0 else mask.shape[0] // 2
    
    @staticmethod
    def normalize_image(img):
        """æ¨™æº–åŒ–åœ–åƒåˆ° 0-1"""
        img_min = np.min(img)
        img_max = np.max(img)
        if img_max - img_min > 0:
            return (img - img_min) / (img_max - img_min)
        return img
    
    @staticmethod
    def generate_comparison_image(image, ground_truth, prediction, output_path, dice_score, viz_cmap='viridis'):
        """Generate comparison image with 4 subplots: original image, ground truth, prediction, overlap with label counts"""
        if not VISUALIZATION_AVAILABLE:
            print(f"   âš ï¸  Skipping visualization (missing dependencies)")
            return
        
        try:
            # Ensure 3D data
            if image.ndim != 3 or ground_truth.ndim != 3 or prediction.ndim != 3:
                print(f"   âš ï¸  Incorrect data dimensions, skipping visualization")
                return
            
            # Select best slice
            if VIZ_SLICE_MODE == 'middle':
                slice_idx = image.shape[0] // 2
            elif VIZ_SLICE_MODE == 'max':
                slice_idx = VisualizationHelper.find_best_slice(ground_truth + prediction)
            else:
                slice_idx = image.shape[0] // 2
            
            # Extract slices
            img_slice = image[slice_idx, :, :]
            gt_slice = ground_truth[slice_idx, :, :]
            pred_slice = prediction[slice_idx, :, :]
            
            # Normalize image
            img_slice = VisualizationHelper.normalize_image(img_slice)
            
            # Create figure with larger size
            fig, axes = plt.subplots(2, 2, figsize=(14, 14), dpi=VIZ_DPI)
            fig.suptitle(f'{Path(output_path).stem} (Dice: {dice_score:.4f})', fontsize=16, fontweight='bold')
            
            # Subplot 1: Original Image
            axes[0, 0].imshow(img_slice, cmap='gray')
            axes[0, 0].set_title('Original Image', fontweight='bold', fontsize=12)
            axes[0, 0].axis('off')
            
            # Subplot 2: Ground Truth
            axes[0, 1].imshow(img_slice, cmap='gray')
            axes[0, 1].imshow(gt_slice, cmap='Reds', alpha=0.6)
            axes[0, 1].set_title('Ground Truth', fontweight='bold', fontsize=12)
            axes[0, 1].axis('off')
            
            # Add label count for ground truth
            gt_count = np.sum(gt_slice > 0)
            axes[0, 1].text(0.02, 0.98, f'Labels: {gt_count}', 
                           transform=axes[0, 1].transAxes,
                           fontsize=11, verticalalignment='top',
                           bbox=dict(boxstyle='round', facecolor='white', alpha=0.9))
            
            # Subplot 3: Prediction
            axes[1, 0].imshow(img_slice, cmap='gray')
            axes[1, 0].imshow(pred_slice, cmap=viz_cmap, alpha=0.6)
            axes[1, 0].set_title('Prediction', fontweight='bold', fontsize=12)
            axes[1, 0].axis('off')
            
            # Add label count for prediction
            pred_count = np.sum(pred_slice > 0)
            axes[1, 0].text(0.02, 0.98, f'Labels: {pred_count}', 
                           transform=axes[1, 0].transAxes,
                           fontsize=11, verticalalignment='top',
                           bbox=dict(boxstyle='round', facecolor='white', alpha=0.9))
            
            # Subplot 4: Overlap (Ground Truth=Red, Prediction=Blue)
            axes[1, 1].imshow(img_slice, cmap='gray')
            
            # Ground Truth - Red
            gt_overlay = np.zeros((*gt_slice.shape, 3), dtype=np.float32)
            gt_overlay[gt_slice > 0, 0] = 1.0  # Red
            axes[1, 1].imshow(gt_overlay, alpha=0.5)
            
            # Prediction - Blue
            pred_overlay = np.zeros((*pred_slice.shape, 3), dtype=np.float32)
            pred_overlay[pred_slice > 0, 2] = 1.0  # Blue
            axes[1, 1].imshow(pred_overlay, alpha=0.5)
            
            axes[1, 1].set_title('Overlap (Red=Ground Truth, Blue=Prediction)', fontweight='bold', fontsize=12)
            axes[1, 1].axis('off')
            
            # Add label information for overlap
            intersection = np.sum((gt_slice > 0) & (pred_slice > 0))
            axes[1, 1].text(0.02, 0.98, f'GT Labels: {gt_count}\nPred Labels: {pred_count}\nIntersection: {intersection}', 
                           transform=axes[1, 1].transAxes,
                           fontsize=10, verticalalignment='top',
                           bbox=dict(boxstyle='round', facecolor='white', alpha=0.9))
            
            # Add legend
            red_patch = mpatches.Patch(color='red', label='Ground Truth', alpha=0.6)
            blue_patch = mpatches.Patch(color='blue', label='Prediction', alpha=0.6)
            fig.legend(handles=[red_patch, blue_patch], loc='lower center', ncol=2, fontsize=11)
            
            plt.tight_layout()
            plt.subplots_adjust(bottom=0.08)
            
            # Save figure
            plt.savefig(output_path, dpi=VIZ_DPI, bbox_inches='tight')
            plt.close()
            
            print(f"   âœ… Saved visualization: {Path(output_path).name}")
            
        except Exception as e:
            print(f"   âš ï¸  Error generating visualization: {e}")
            import traceback
            traceback.print_exc()


def run_inference_with_visualization():
    """åŸ·è¡Œæ¨ç†çš„ä¸»å‡½æ•¸ï¼ˆæ·»åŠ å¯è¦–åŒ–ï¼‰"""

    seed = 42
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
    
    print("\n" + "="*70)
    print("ğŸš€ é–‹å§‹æ¨ç†æ¸¬è©¦ï¼ˆä½¿ç”¨è¨“ç·´æ™‚ç›¸åŒçš„é è™•ç†æ–¹å¼ï¼‰")
    print("="*70)
    
    # é©—è­‰é…ç½®
    print("\nğŸ“‹ é©—è­‰é…ç½®...")
    if not Path(MODEL_PATH).exists():
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {MODEL_PATH}")
        return None
    
    if not Path(IMAGES_DIR).exists():
        print(f"âŒ å½±åƒæ–‡ä»¶å¤¾ä¸å­˜åœ¨: {IMAGES_DIR}")
        return None
    
    masks_dir = MASKS_DIR if Path(MASKS_DIR).exists() else None
    if MASKS_DIR and not masks_dir:
        print(f"âš ï¸  é®ç½©æ–‡ä»¶å¤¾ä¸å­˜åœ¨: {MASKS_DIR}ï¼Œå°‡ä¸è¨ˆç®—æŒ‡æ¨™")
    
    print(f"âœ… é…ç½®é©—è­‰é€šé")
    print(f"   ğŸ“ æ¨¡å‹è·¯å¾‘: {MODEL_PATH}")
    print(f"   ğŸ“ å½±åƒæ–‡ä»¶å¤¾: {IMAGES_DIR}")
    if masks_dir:
        print(f"   ğŸ“ é®ç½©æ–‡ä»¶å¤¾: {MASKS_DIR}")
    print(f"   ğŸ–¥ï¸  è¨ˆç®—è¨­å‚™: {DEVICE}")
    print(f"   ğŸ“Š æ¨¡å‹é…ç½®: {MODEL_CONFIG}")
    print(f"   ğŸ“ ç›®æ¨™å°ºå¯¸: {TARGET_SIZE}")
    if SPACING:
        print(f"   ğŸ”„ Spacing (z,y,x): {SPACING}")
    print(f"   ğŸ¨ ç”Ÿæˆå¯è¦–åŒ–: {GENERATE_VISUALIZATIONS}")
    
    try:
        # åˆå§‹åŒ–æ¨ç†å™¨
        print("\nğŸ”§ åˆå§‹åŒ–æ¨ç†å™¨...")
        inferencer = ModelInference(
            model_path=MODEL_PATH,
            config=MODEL_CONFIG,
            device=DEVICE,
            spacing=SPACING,
            force_separate_z=FORCE_SEPARATE_Z
        )
        
        # åŸ·è¡Œæ¨ç†
        print("\nâ–¶ï¸  åŸ·è¡Œæ¨ç†...")
        results, summary = inferencer.infer_folder(
            images_folder=IMAGES_DIR,
            masks_folder=masks_dir,
            target_size=TARGET_SIZE,
            save_results=SAVE_RESULTS,
            output_dir=OUTPUT_DIR
        )
        
        # ç”Ÿæˆå¯è¦–åŒ–å’Œå ±å‘Š
        if summary:
            print("\nğŸ“Š å¾Œè™•ç†çµæœ...")
            _save_detailed_reports(results, summary, OUTPUT_DIR, masks_dir)
            
            if GENERATE_VISUALIZATIONS and VISUALIZATION_AVAILABLE:
                print("\nğŸ¨ ç”Ÿæˆå¯è¦–åŒ–åœ–ç‰‡...")
                _generate_all_visualizations(results, IMAGES_DIR, masks_dir, OUTPUT_DIR)
            
            # é¡¯ç¤ºçµæœ
            print("\n" + "="*70)
            print("âœ… æ¨ç†å®Œæˆï¼")
            print("="*70)
            print(f"ç¸½æ¨£æœ¬æ•¸: {summary['total_samples']}")
            print(f"å¹³å‡ Dice: {summary['avg_dice']:.6f} ({summary['avg_dice']*100:.2f}%)")
            print(f"æ¨™æº–å·®: {summary['std_dice']:.6f}")
            print(f"æœ€ä½³ Dice: {summary['max_dice']:.6f}")
            print(f"æœ€å·® Dice: {summary['min_dice']:.6f}")
            print("="*70)
            
            # é¡¯ç¤ºå€‹åˆ¥çµæœ
            print("\nğŸ“Š å€‹åˆ¥çµæœ:")
            print(f"{'æ¨£æœ¬åç¨±':<40} {'Diceåˆ†æ•¸':<15}")
            print("-" * 55)
            for result in results:
                image_name = Path(result['image_path']).name
                if 'metrics' in result:
                    dice = result['metrics']['mean_dice']
                    print(f"{image_name:<40} {dice:<15.6f}")
                else:
                    print(f"{image_name:<40} {'N/A':<15}")
            
            # é¡¯ç¤ºä¿å­˜ä½ç½®
            if SAVE_RESULTS:
                output_path = Path(OUTPUT_DIR)
                print(f"\nğŸ’¾ çµæœå·²ä¿å­˜åˆ°: {output_path}")
                print(f"   - JSON å ±å‘Š: {list(output_path.glob('inference_summary_*.json'))}")
                print(f"   - TXT å ±å‘Š: {list(output_path.glob('dice_scores_*.txt'))}")
                if GENERATE_VISUALIZATIONS:
                    print(f"   - å¯è¦–åŒ–åœ–ç‰‡: {list(output_path.glob('viz_*.png'))}")
            
            return results, summary
        else:
            print("âŒ æ¨ç†å¤±æ•—æˆ–æ²’æœ‰è¨ˆç®—æŒ‡æ¨™")
            return results, None
    
    except Exception as e:
        print(f"\nâŒ æ¨ç†éç¨‹ä¸­å‡ºéŒ¯: {e}")
        import traceback
        traceback.print_exc()
        return None, None


def _save_detailed_reports(results, summary, output_dir, masks_dir):
    """ä¿å­˜è©³ç´°çš„ txt å ±å‘Šå’Œ JSON å ±å‘Š"""
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # ========== ä¿å­˜ TXT å ±å‘Š ==========
    txt_file = output_path / f"dice_scores_{timestamp}.txt"
    
    with open(txt_file, 'w', encoding='utf-8') as f:
        f.write("="*70 + "\n")
        f.write("ğŸ”¬ æ¨ç†çµæœå ±å‘Š\n")
        f.write("="*70 + "\n\n")
        
        f.write(f"ç”Ÿæˆæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"æ¨¡å‹é…ç½®:\n")
        f.write(f"  - è¼¸å…¥é€šé“æ•¸: {MODEL_CONFIG['n_channels']}\n")
        f.write(f"  - è¼¸å‡ºé¡åˆ¥æ•¸: {MODEL_CONFIG['n_classes']}\n")
        f.write(f"  - åŸºç¤é€šé“æ•¸: {MODEL_CONFIG['base_channels']}\n")
        f.write(f"  - GroupNorm çµ„æ•¸: {MODEL_CONFIG['num_groups']}\n")
        f.write(f"  - é›™ç·šæ€§ä¸Šæ¡æ¨£: {MODEL_CONFIG['bilinear']}\n")
        f.write(f"\n")
        
        # æ‘˜è¦çµ±è¨ˆ
        f.write("="*70 + "\n")
        f.write("ğŸ“Š æ‘˜è¦çµ±è¨ˆ\n")
        f.write("="*70 + "\n")
        f.write(f"ç¸½æ¨£æœ¬æ•¸: {summary['total_samples']}\n")
        f.write(f"å¹³å‡ Dice åˆ†æ•¸: {summary['avg_dice']:.6f}\n")
        f.write(f"æ¨™æº–å·®: {summary['std_dice']:.6f}\n")
        f.write(f"æœ€é«˜ Dice åˆ†æ•¸: {summary['max_dice']:.6f}\n")
        f.write(f"æœ€ä½ Dice åˆ†æ•¸: {summary['min_dice']:.6f}\n")
        f.write(f"\n")
        
        # å€‹åˆ¥æ¨£æœ¬è©³ç´°çµæœ
        f.write("="*70 + "\n")
        f.write("ğŸ“‹ å€‹åˆ¥æ¨£æœ¬è©³ç´°çµæœ\n")
        f.write("="*70 + "\n")
        f.write(f"{'åºè™Ÿ':<5} {'æ¨£æœ¬åç¨±':<35} {'Diceåˆ†æ•¸':<15}\n")
        f.write("-"*55 + "\n")
        
        for idx, result in enumerate(results, 1):
            image_name = Path(result['image_path']).name
            if 'metrics' in result:
                dice = result['metrics']['mean_dice']
                f.write(f"{idx:<5} {image_name:<35} {dice:<15.6f}\n")
            else:
                f.write(f"{idx:<5} {image_name:<35} {'N/A':<15}\n")
        
        f.write("\n" + "="*70 + "\n")
        f.write("ğŸ“ æ³¨é‡‹\n")
        f.write("="*70 + "\n")
        f.write(f"- Dice åˆ†æ•¸ç¯„åœ: 0-1 (è¶Šæ¥è¿‘ 1 è¶Šå¥½)\n")
        f.write(f"- å¯è¦–åŒ–åœ–ç‰‡ä¿å­˜ä½ç½®: {output_path / 'visualizations'}\n")
        f.write(f"- JSON è©³ç´°å ±å‘Š: inference_summary_{timestamp}.json\n")
    
    print(f"   âœ… å·²ä¿å­˜ TXT å ±å‘Š: {txt_file}")
    
    return txt_file


def _generate_all_visualizations(results, images_dir, masks_dir, output_dir):
    """ç‚ºæ‰€æœ‰çµæœç”Ÿæˆå¯è¦–åŒ–åœ–ç‰‡"""
    viz_dir = Path(output_dir) / 'visualizations'
    viz_dir.mkdir(parents=True, exist_ok=True)
    
    images_path = Path(images_dir)
    masks_path = Path(masks_dir) if masks_dir else None
    
    for idx, result in enumerate(results, 1):
        try:
            if 'output' in result:
                output_debug = result['output']
                if output_debug.ndim == 5:
                    output_debug = output_debug[0, 0]
                elif output_debug.ndim == 4:
                    output_debug = output_debug[0]
                
                output_sigmoid_debug = 1 / (1 + np.exp(-output_debug))
                
                # if idx == 1:  # åªæ‰“å°ç¬¬ä¸€å€‹æ¨£æœ¬
                #     print(f"\nğŸ” è¨ºæ–·ä¿¡æ¯ (æ¨£æœ¬ {idx}):")
                #     print(f"   è¼¸å‡ºå€¼ç¯„åœ: {output_debug.min():.4f} ~ {output_debug.max():.4f}")
                #     print(f"   Sigmoid ç¯„åœ: {output_sigmoid_debug.min():.4f} ~ {output_sigmoid_debug.max():.4f}")
                #     for threshold in [0.1, 0.2, 0.3, 0.4, 0.5]:
                #         count = np.sum(output_sigmoid_debug > threshold)
                #         print(f"   é–¾å€¼ {threshold}: {count} å€‹åƒç´ ")

            image_path = Path(result['image_path'])
            image_name = image_path.stem
            
            # è¼‰å…¥åŸå§‹å½±åƒ
            original_image = VisualizationHelper.load_nii_image(image_path)
            if original_image is None:
                continue
            
            # è¼‰å…¥çœŸå¯¦æ¨™ç±¤
            if masks_path and masks_path.exists():
                mask_path = masks_path / image_path.name
                if mask_path.exists():
                    ground_truth = VisualizationHelper.load_nii_image(mask_path)
                else:
                    ground_truth = None
            else:
                ground_truth = None
            
            # å¾çµæœä¸­æå–é æ¸¬
            if 'output' in result:
                # output å½¢ç‹€ç‚º [1, 1, D, H, W]ï¼ˆbatch, channel, depth, height, widthï¼‰
                output = result['output']
                if output.ndim == 5:
                    output = output[0, 0]  # ç§»é™¤ batch å’Œ channel ç¶­åº¦
                elif output.ndim == 4:
                    output = output[0]  # åªç§»é™¤ batch ç¶­åº¦
                
                # æ‡‰ç”¨ softmax ä¸¦å–æœ€å¤§å€¼
                output_softmax = 1 / (1 + np.exp(-output))  # ç°¡å–®çš„ sigmoid
                prediction = (output_softmax > 0.5).astype(np.uint8)
            else:
                prediction = None
            
            if original_image is None or prediction is None:
                continue
            
            # ç¢ºä¿å°ºå¯¸ä¸€è‡´ï¼ˆå¦‚æœåŸå§‹å½±åƒå°ºå¯¸ä¸åŒï¼Œéœ€è¦èª¿æ•´ï¼‰
            if original_image.shape != prediction.shape:
                # ä½¿ç”¨æœ€è¿‘é„°æ’å€¼èª¿æ•´é æ¸¬å°ºå¯¸åˆ°åŸå§‹å½±åƒå°ºå¯¸
                from scipy.ndimage import zoom
                scale_factors = np.array(original_image.shape) / np.array(prediction.shape)
                prediction = zoom(prediction.astype(float), scale_factors, order=0, mode='constant', cval=0.0).astype(np.uint8)
            
            if ground_truth is not None and ground_truth.shape != original_image.shape:
                from scipy.ndimage import zoom
                scale_factors = np.array(original_image.shape) / np.array(ground_truth.shape)
                ground_truth = zoom(ground_truth.astype(float), scale_factors, order=0).astype(np.uint8)
            
            # ç”Ÿæˆå¯è¦–åŒ–
            dice_score = result['metrics']['mean_dice'] if 'metrics' in result else 0.0
            output_path = viz_dir / f"viz_{idx:03d}_{image_name}.png"
            
            if ground_truth is not None:
                VisualizationHelper.generate_comparison_image(
                    original_image, ground_truth, prediction, output_path, dice_score, viz_cmap=VIZ_CMAP
                )
            else:
                print(f"   âš ï¸  è·³é {image_name}ï¼ˆæ²’æœ‰çœŸå¯¦æ¨™ç±¤ï¼‰")
        
        except Exception as e:
            print(f"   âš ï¸  ç”Ÿæˆ {Path(result['image_path']).name} çš„å¯è¦–åŒ–æ™‚å‡ºéŒ¯: {e}")


def run_single_sample_inference(image_path, mask_path=None):
    """
    æ¨ç†å–®å€‹æ¨£æœ¬çš„å‡½æ•¸
    
    Args:
        image_path: å–®å€‹å½±åƒçš„è·¯å¾‘
        mask_path: å°æ‡‰çš„é®ç½©è·¯å¾‘ï¼ˆå¯é¸ï¼‰
        
    Returns:
        dict: æ¨ç†çµæœ
    """
    
    print("\n" + "="*70)
    print("ğŸš€ æ¨ç†å–®å€‹æ¨£æœ¬ï¼ˆä½¿ç”¨è¨“ç·´æ™‚ç›¸åŒçš„é è™•ç†æ–¹å¼ï¼‰")
    print("="*70)
    
    try:
        # åˆå§‹åŒ–æ¨ç†å™¨
        print("ğŸ”§ åˆå§‹åŒ–æ¨ç†å™¨...")
        inferencer = ModelInference(
            model_path=MODEL_PATH,
            config=MODEL_CONFIG,
            device=DEVICE,
            spacing=SPACING,
            force_separate_z=FORCE_SEPARATE_Z
        )
        
        # æ¨ç†å–®å€‹æ¨£æœ¬
        print(f"\nâ–¶ï¸  æ¨ç†æ¨£æœ¬: {Path(image_path).name}")
        result = inferencer.infer_single_sample(
            image_path=image_path,
            mask_path=mask_path,
            target_size=TARGET_SIZE
        )
        
        if result:
            print("\n" + "="*70)
            print("âœ… æ¨ç†å®Œæˆï¼")
            print("="*70)
            
            if 'metrics' in result:
                metrics = result['metrics']
                print(f"å¹³å‡ Dice: {metrics['mean_dice']:.6f}")
                if 'per_class_dice' in metrics:
                    print(f"é¡åˆ¥ Dice: {metrics['per_class_dice']}")
            
            print(f"è¼¸å‡ºå½¢ç‹€: {result['output'].shape}")
            print("="*70)
            
            return result
        else:
            print("âŒ æ¨ç†å¤±æ•—")
            return None
    
    except Exception as e:
        print(f"âŒ æ¨ç†éç¨‹ä¸­å‡ºéŒ¯: {e}")
        import traceback
        traceback.print_exc()
        return None


# ========================================
# ä¸»ç¨‹å¼
# ========================================

if __name__ == '__main__':
    import sys
    
    # æª¢æŸ¥å‘½ä»¤è¡Œåƒæ•¸
    if len(sys.argv) > 1:
        if sys.argv[1] == 'single' and len(sys.argv) > 2:
            # æ¨ç†å–®å€‹æ¨£æœ¬
            image_path = sys.argv[2]
            mask_path = sys.argv[3] if len(sys.argv) > 3 else None
            result = run_single_sample_inference(image_path, mask_path)
        else:
            print("âŒ ä¸æ”¯æ´çš„å‘½ä»¤")
            print("\nä½¿ç”¨æ–¹å¼:")
            print("  python test_inference_enhanced.py           # æ¨ç†æ•´å€‹æ–‡ä»¶å¤¾")
            print("  python test_inference_enhanced.py single <image_path> [mask_path]  # æ¨ç†å–®å€‹æ¨£æœ¬")
    else:
        # æ¨ç†æ•´å€‹æ–‡ä»¶å¤¾ï¼ˆå«å¯è¦–åŒ–ï¼‰
        results, summary = run_inference_with_visualization()
    
    """
    âœ¨ æ–°å¢åŠŸèƒ½ï¼š
    
    1ï¸âƒ£ è‡ªå‹•ç”Ÿæˆ TXT å ±å‘Šï¼š
       - ä¿å­˜æ‰€æœ‰æ¨£æœ¬çš„ Dice åˆ†æ•¸
       - è¨ˆç®—å¹³å‡å€¼ã€æ¨™æº–å·®ã€æœ€å¤§å€¼ã€æœ€å°å€¼
       - åŒ…å«æ¨¡å‹é…ç½®å’Œæ™‚é–“æˆ³
       - æª”æ¡ˆåç¨±ï¼šdice_scores_YYYYMMDD_HHMMSS.txt
    
    2ï¸âƒ£ è‡ªå‹•ç”Ÿæˆå¯è¦–åŒ–åœ–ç‰‡ï¼š
       - å››å€‹å­åœ–ï¼šåŸå§‹å½±åƒã€çœŸå¯¦æ¨™ç±¤ã€é æ¸¬æ¨™ç±¤ã€é‡ç–Š
       - æ”¯æ´å¤šç¨®åˆ‡ç‰‡é¸æ“‡æ¨¡å¼
       - è‡ªå‹•èª¿æ•´é æ¸¬çµæœå°ºå¯¸åˆ°åŸå§‹å½±åƒå°ºå¯¸
       - æª”æ¡ˆåç¨±ï¼šviz_XXX_sample_name.png
       - ä¿å­˜ä½ç½®ï¼š{OUTPUT_DIR}/visualizations/
    
    3ï¸âƒ£ åŸå‡½æ•¸åç¨±ä¿æŒä¸è®Šï¼š
       - run_inference_with_visualization() (æ–°å¢ï¼ŒåŸæœ¬ run_inference())
       - run_single_sample_inference() (ä¿ç•™)
    
    ğŸ“Š TXT å ±å‘Šå…§å®¹åŒ…æ‹¬ï¼š
       - æ¨¡å‹é…ç½®ï¼ˆé€šé“æ•¸ã€é¡åˆ¥æ•¸ã€åŸºç¤é€šé“ç­‰ï¼‰
       - æ‘˜è¦çµ±è¨ˆï¼ˆå¹³å‡ã€æ¨™æº–å·®ã€æœ€å¤§ã€æœ€å° Diceï¼‰
       - å€‹åˆ¥æ¨£æœ¬çµæœï¼ˆåºè™Ÿã€åç¨±ã€Dice åˆ†æ•¸ï¼‰
       - æ™‚é–“æˆ³å’Œæ³¨é‡‹
    
    ğŸ¨ å¯è¦–åŒ–ç‰¹æ€§ï¼š
       - æ™ºèƒ½é¸æ“‡æœ€ä½³åˆ‡ç‰‡é¡¯ç¤º
       - æ”¯æ´å½©è‰²ç–ŠåŠ ï¼ˆç´…è‰²=çœŸå¯¦ï¼Œè—è‰²=é æ¸¬ï¼‰
       - é«˜åˆ†è¾¨ç‡è¼¸å‡ºï¼ˆå¯é…ç½® DPIï¼‰
       - è‡ªå‹•è™•ç†å°ºå¯¸ä¸åŒ¹é…
    
    âš ï¸  ä¾è³´è¦æ±‚ï¼š
       - nibabel (è¼‰å…¥ NII æ–‡ä»¶)
       - scipy (åœ–åƒç¸®æ”¾)
       - matplotlib (ç¹ªåœ–)
       
       å®‰è£ï¼špip install nibabel scipy matplotlib
    """