#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¨ç†è…³æœ¬ - ä½¿ç”¨è¨“ç·´å¥½çš„æ¨¡å‹å°æ–°æ¨£æœ¬é€²è¡Œæ¨ç†
âœ… ç›´æ¥ä½¿ç”¨è¨“ç·´æ™‚çš„æ•¸æ“šè®€å–å™¨ï¼ˆnnUNet é¢¨æ ¼ resamplingï¼‰
âœ… ä½¿ç”¨ Argmaxï¼ˆèˆ‡è¨“ç·´æ™‚å®Œå…¨ä¸€è‡´ï¼‰
æ”¯æ´å–®å€‹æ¨£æœ¬ã€æ•´å€‹æ–‡ä»¶å¤¾æ¸¬è©¦
"""

import torch
import numpy as np
from pathlib import Path
from datetime import datetime
import argparse
import json

try:
    from tqdm import tqdm
    TQDM_AVAILABLE = True
except ImportError:
    TQDM_AVAILABLE = False

# âœ… æ ¹æ“šä½ çš„é …ç›®çµæ§‹å°å…¥
from src.network_architecture.unet3d import UNet3D
from src.data_processing_and_data_enhancement.dataload import MedicalImageDataset
from src.loss_architecture.loss import CombinedLoss, DiceLoss
from src.loss_architecture.calculate_dice import calculate_metrics


class ModelInference:
    """æ¨¡å‹æ¨ç†é¡ï¼ˆä½¿ç”¨è¨“ç·´æ™‚ç›¸åŒçš„é è™•ç†æ–¹å¼ï¼‰"""
    
    def __init__(self, model_path, config=None, device='auto', 
                 spacing=None, force_separate_z=None):
        """
        åˆå§‹åŒ–æ¨ç†å™¨
        
        Args:
            model_path: è¨“ç·´å¥½çš„æ¨¡å‹æ¬Šé‡è·¯å¾‘
            config: æ¨¡å‹é…ç½®ï¼ˆåŒ…å«æ¨¡å‹è¶…åƒæ•¸ï¼‰
            device: è¨ˆç®—è¨­å‚™ ('auto', 'cuda', 'cpu')
            spacing: åŸå§‹è³‡æ–™çš„ spacing (z, y, x) - ç”¨æ–¼å„å‘ç•°æ€§è™•ç†
            force_separate_z: å¼·åˆ¶æ˜¯å¦åˆ†é›¢ z è»¸è™•ç†
        """
        self.device = self._setup_device(device)
        self.model = None
        self.config = config or {}
        self.criterion = None
        
        # ä¿å­˜ resampling ç›¸é—œåƒæ•¸
        self.spacing = spacing if spacing is not None else [1.0, 1.0, 1.0]
        self.force_separate_z = force_separate_z
        
        # è¼‰å…¥æ¨¡å‹
        self._load_model(model_path)
        print(f"âœ… æ¨¡å‹å·²è¼‰å…¥: {model_path}")
    
    def _setup_device(self, device):
        """è¨­ç½®è¨ˆç®—è¨­å‚™"""
        if device == 'auto':
            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        else:
            device = torch.device(device)
        
        print(f"ğŸ–¥ï¸  ä½¿ç”¨è¨­å‚™: {device}")
        if device.type == 'cuda':
            print(f"ğŸ’¾ GPU åç¨±: {torch.cuda.get_device_name(device)}")
        
        return device
    
    def _load_model(self, model_path):
        """è¼‰å…¥æ¨¡å‹æ¬Šé‡ï¼ˆä¿®å¾©ç‰ˆæœ¬ï¼šè™•ç† total_ops å’Œ total_paramsï¼‰"""
        print("ğŸ“‚ è¼‰å…¥æ¨¡å‹...")
        checkpoint = torch.load(model_path, map_location=self.device, weights_only=False)
        
        # ç²å–æ¨¡å‹é…ç½®ï¼ˆå¾æª¢æŸ¥é»ä¸­æå–ï¼‰
        if 'model_config' in checkpoint:
            model_config = checkpoint['model_config']
            print(f"ğŸ“‹ å¾æª¢æŸ¥é»ä¸­è¼‰å…¥æ¨¡å‹é…ç½®")
        else:
            # å¦‚æœæ²’æœ‰ä¿å­˜é…ç½®ï¼Œä½¿ç”¨é»˜èªå€¼
            model_config = {
                'n_channels': self.config.get('n_channels', 1),
                'n_classes': self.config.get('n_classes', 2),
                'base_channels': self.config.get('base_channels', 32),
                'num_groups': self.config.get('num_groups', 8),
                'bilinear': self.config.get('bilinear', False)
            }
            print(f"âš ï¸  ä½¿ç”¨é»˜èªæ¨¡å‹é…ç½®")
        
        # ä¿å­˜é…ç½®
        self.config.update(model_config)
        
        # å»ºç«‹æ¨¡å‹
        print("ğŸ—ï¸  å»ºç«‹æ¨¡å‹æ¶æ§‹...")
        self.model = UNet3D(
            n_channels=model_config['n_channels'],
            n_classes=model_config['n_classes'],
            base_channels=model_config['base_channels'],
            num_groups=model_config['num_groups'],
            bilinear=model_config['bilinear']
        ).to(self.device)
        
        # è¼‰å…¥æ¬Šé‡ï¼ˆé—œéµä¿®å¾©ï¼šç§»é™¤å¤šé¤˜çš„çµ±è¨ˆä¿¡æ¯éµï¼‰
        print("âš™ï¸  è¼‰å…¥æ¨¡å‹æ¬Šé‡...")
        model_state_dict = checkpoint['model_state_dict']
        
        # âœ… ç§»é™¤æ‰€æœ‰åŒ…å« 'total_ops' å’Œ 'total_params' çš„éµ
        keys_to_remove = [key for key in model_state_dict.keys() 
                         if 'total_ops' in key or 'total_params' in key]
        
        if keys_to_remove:
            print(f"ğŸ§¹ ç™¼ç¾ {len(keys_to_remove)} å€‹å¤šé¤˜çš„çµ±è¨ˆä¿¡æ¯éµï¼Œæ­£åœ¨æ¸…ç†...")
            for key in keys_to_remove:
                del model_state_dict[key]
            print(f"âœ… æ¸…ç†å®Œæˆï¼Œé–‹å§‹è¼‰å…¥æ¬Šé‡...")
        
        # è¼‰å…¥æ¸…ç†å¾Œçš„ç‹€æ…‹å­—å…¸
        try:
            self.model.load_state_dict(model_state_dict)
            print("âœ… æ¨¡å‹æ¬Šé‡è¼‰å…¥æˆåŠŸ")
        except RuntimeError as e:
            print(f"âš ï¸  è­¦å‘Šï¼šè¼‰å…¥æ™‚å‡ºç¾ä¸åŒ¹é…")
            self.model.load_state_dict(model_state_dict, strict=False)
            print("âœ… å·²ä½¿ç”¨éåš´æ ¼æ¨¡å¼è¼‰å…¥æ¨¡å‹")
        
        self.model.eval()
        
        print(f"ğŸ“Š æ¨¡å‹é…ç½®: n_channels={model_config['n_channels']}, "
              f"n_classes={model_config['n_classes']}")
    
    def _load_data_with_dataset_class(self, image_path, mask_path=None, target_size=(64, 64, 64)):
        """
        ä½¿ç”¨ MedicalImageDataset é¡ä¾†è¼‰å…¥æ•¸æ“š
        âœ… ä¿è­‰èˆ‡è¨“ç·´æ™‚ç›¸åŒçš„é è™•ç†æ–¹å¼
        âœ… ç¢ºä¿æ­£ç¢ºçš„ç¶­åº¦ [C, D, H, W]
        """
        try:
            import nibabel as nib
            
            print(f"   ğŸ“‚ è¼‰å…¥å½±åƒ: {Path(image_path).name}")
            
            # ç›´æ¥è¼‰å…¥ä¸¦ä½¿ç”¨ MedicalImageDataset çš„é è™•ç†é‚è¼¯
            image = self._load_nii_image(image_path)
            
            # è¼‰å…¥é®ç½©ï¼ˆå¦‚æœæä¾›äº†ï¼‰
            mask = None
            if mask_path and Path(mask_path).exists():
                print(f"   ğŸ“‚ è¼‰å…¥é®ç½©: {Path(mask_path).name}")
                mask = self._load_nii_image(mask_path)
            
            # è¨˜éŒ„åŸå§‹å°ºå¯¸
            original_size = image.shape
            
            # âœ… ä½¿ç”¨èˆ‡è¨“ç·´ç›¸åŒçš„ resampling æ–¹å¼
            image_resized = self._resize_volume(image, target_size, is_seg=False)
            mask_resized = None
            if mask is not None:
                mask_resized = self._resize_volume(mask, target_size, is_seg=True)
            
            # âœ… ä½¿ç”¨èˆ‡è¨“ç·´ç›¸åŒçš„æ¨™æº–åŒ–æ–¹å¼
            image_normalized = self._normalize_image(image_resized)
            
            # âœ… æ¸…ç†æ¨™ç±¤ï¼ˆèˆ‡è¨“ç·´ç›¸åŒï¼‰
            if mask_resized is not None:
                mask_resized = self._clean_labels(mask_resized)
            
            # æ·»åŠ é€šé“ç¶­åº¦ [1, D, H, W]
            image_tensor = torch.from_numpy(image_normalized[np.newaxis, ...]).float()
            
            if mask_resized is not None:
                mask_tensor = torch.from_numpy(mask_resized).long()
            else:
                mask_tensor = None
            
            print(f"   âœ… æ•¸æ“šè¼‰å…¥æˆåŠŸ: å½±åƒå½¢ç‹€={image_tensor.shape}, é®ç½©={'æ˜¯' if mask_resized is not None else 'å¦'}")
            
            return image_tensor, mask_tensor, original_size
            
        except Exception as e:
            print(f"   âŒ è¼‰å…¥æ•¸æ“šå¤±æ•—: {e}")
            import traceback
            traceback.print_exc()
            return None, None, None
    
    def _load_nii_image(self, file_path):
        """è¼‰å…¥ NII.GZ æª”æ¡ˆï¼ˆèˆ‡è¨“ç·´æ™‚ç›¸åŒï¼‰"""
        import nibabel as nib
        
        nii_img = nib.load(str(file_path))
        img_data = nii_img.get_fdata()
        img_data = np.array(img_data, dtype=np.float32)
        
        # æå– spacing è³‡è¨Š
        if self.spacing is None or np.allclose(self.spacing, [1.0, 1.0, 1.0]):
            file_spacing = nii_img.header.get_zooms()[:3]
            self.spacing = [float(file_spacing[2]), float(file_spacing[1]), float(file_spacing[0])]
        
        if img_data.ndim == 4:
            img_data = img_data[:, :, :, 0]
        elif img_data.ndim < 3:
            raise ValueError(f"åœ–åƒç¶­åº¦éä½: {img_data.ndim}D")
        
        return img_data
    
    def _normalize_image(self, image):
        """å½±åƒæ¨™æº–åŒ–ï¼ˆèˆ‡è¨“ç·´æ™‚ç›¸åŒï¼‰"""
        p1, p99 = np.percentile(image, (1, 99))
        image = np.clip(image, p1, p99)
        
        mean = np.mean(image)
        std = np.std(image)
        if std > 0:
            image = (image - mean) / std
        
        return image
    
    def _clean_labels(self, mask):
        """æ¸…ç†æ¨™ç±¤ï¼ˆèˆ‡è¨“ç·´æ™‚ç›¸åŒï¼‰"""
        if mask.ndim == 4:
            mask = mask[:, :, :, 0]
        
        mask = np.nan_to_num(mask, nan=0.0, posinf=0.0, neginf=0.0)
        mask[mask > 0] = 1
        mask = mask.astype(np.int64)
        
        return mask
    
    def _resize_volume(self, volume, target_size, is_seg=False):
        """
        ä½¿ç”¨ nnUNet é¢¨æ ¼çš„ resamplingï¼ˆèˆ‡è¨“ç·´æ™‚ç›¸åŒï¼‰
        æ”¯æ´å„å‘ç•°æ€§è™•ç†
        """
        from src.data_processing_and_data_enhancement.dataload import resample_data_or_seg, determine_do_sep_z_and_axis
        
        if target_size is None:
            return volume
        
        if volume.ndim != 3:
            raise ValueError(f"resize_volume åªæ”¯æ´3Dé«”ç©ï¼Œæ”¶åˆ° {volume.ndim}D")
        
        current_size = volume.shape
        
        if len(target_size) != 3:
            raise ValueError(f"target_size å¿…é ˆæ˜¯3D (D, H, W)")
        
        # è¨ˆç®—æ–°çš„ spacing
        current_spacing = np.array(self.spacing)
        new_spacing = current_spacing * (np.array(current_size) / np.array(target_size))
        
        # æ±ºå®šæ˜¯å¦éœ€è¦åˆ†é›¢ z è»¸
        do_separate_z, axis = determine_do_sep_z_and_axis(
            self.force_separate_z, 
            current_spacing, 
            new_spacing
        )
        
        # ä½¿ç”¨ nnUNet é¢¨æ ¼çš„ resampling
        order = 0 if is_seg else 3
        order_z = 0
        
        resized = resample_data_or_seg(
            volume,
            target_size,
            is_seg=is_seg,
            axis=axis,
            order=order,
            do_separate_z=do_separate_z,
            order_z=order_z
        )
        
        return resized
    
    def get_prediction_as_binary(self, output):
        """
        âœ… æ–°å¢æ–¹æ³•ï¼šä½¿ç”¨ Argmax å°‡æ¨¡å‹è¼¸å‡ºè½‰ç‚ºäºŒå€¼é æ¸¬
        èˆ‡è¨“ç·´æ™‚çš„ calculate_dice_score å®Œå…¨ä¸€è‡´
        
        Args:
            output: æ¨¡å‹è¼¸å‡º [B, C, D, H, W] æˆ– [C, D, H, W]
            
        Returns:
            prediction: äºŒå€¼é æ¸¬ [D, H, W]ï¼Œå€¼ç‚º 0 æˆ– 1
        """
        # ç¢ºä¿æ˜¯ numpy array
        if isinstance(output, torch.Tensor):
            output = output.cpu().numpy()
        
        # ç§»é™¤ batch ç¶­åº¦ï¼ˆå¦‚æœæœ‰ï¼‰
        if output.ndim == 5:
            output = output[0]  # [C, D, H, W]
        
        # ä½¿ç”¨ argmax å–å¾—é æ¸¬é¡åˆ¥ï¼ˆèˆ‡è¨“ç·´æ™‚ä¸€è‡´ï¼‰
        prediction = np.argmax(output, axis=0)  # [D, H, W]
        
        return prediction.astype(np.uint8)
    
    def infer_single_sample(self, image_path, mask_path=None, target_size=(64, 64, 64)):
        """
        å°å–®å€‹æ¨£æœ¬é€²è¡Œæ¨ç†
        âœ… ä½¿ç”¨è¨“ç·´æ™‚ç›¸åŒçš„é è™•ç†æ–¹å¼
        âœ… ä½¿ç”¨ Argmaxï¼ˆèˆ‡è¨“ç·´æ™‚ä¸€è‡´ï¼‰
        
        Args:
            image_path: å½±åƒè·¯å¾‘
            mask_path: é®ç½©è·¯å¾‘ï¼ˆå¯é¸ï¼Œç”¨æ–¼è¨ˆç®—æŒ‡æ¨™ï¼‰
            target_size: ç›®æ¨™å°ºå¯¸
            
        Returns:
            dict: æ¨ç†çµæœ
        """
        print(f"\nğŸ“Š æ¨ç†æ¨£æœ¬: {Path(image_path).name}")
        
        # è¼‰å…¥æ•¸æ“šï¼ˆä½¿ç”¨è¨“ç·´æ™‚ç›¸åŒçš„æ–¹å¼ï¼‰
        image, mask, original_size = self._load_data_with_dataset_class(
            image_path, mask_path, target_size
        )
        
        if image is None:
            return None
        
        # âœ… ç¢ºä¿æœ‰æ‰¹æ¬¡ç¶­åº¦ [1, C, D, H, W]
        if image.ndim == 4:
            image = image.unsqueeze(0)
            if mask is not None:
                mask = mask.unsqueeze(0)
        elif image.ndim != 5:
            print(f"âŒ éŒ¯èª¤çš„å½±åƒç¶­åº¦: {image.ndim}D, æœŸæœ› 4D æˆ– 5D")
            return None
        
        print(f"   ğŸ“ æœ€çµ‚å½¢ç‹€: {image.shape} (éœ€è¦ [B, C, D, H, W])")
        
        # ç§»åˆ°è¨­å‚™
        image = image.to(self.device)
        if mask is not None:
            mask = mask.to(self.device)
        
        # å‰å‘å‚³æ’­
        with torch.no_grad():
            output = self.model(image)
        
        # âœ… ä½¿ç”¨ Argmax ç”ŸæˆäºŒå€¼é æ¸¬ï¼ˆèˆ‡è¨“ç·´ä¸€è‡´ï¼‰
        prediction_binary = self.get_prediction_as_binary(output)
        
        result = {
            'image_path': str(image_path),
            'output': output.cpu().numpy(),  # ä¿å­˜åŸå§‹è¼¸å‡ºï¼ˆç”¨æ–¼é€²ä¸€æ­¥åˆ†æï¼‰
            'prediction': prediction_binary,  # ä¿å­˜äºŒå€¼é æ¸¬ï¼ˆç”¨æ–¼å¯è¦–åŒ–ï¼‰
            'image': image.cpu().numpy(),
        }
        
        # å¦‚æœæä¾›é®ç½©ï¼Œè¨ˆç®—æŒ‡æ¨™
        if mask is not None:
            result['mask'] = mask.cpu().numpy()
            
            # âœ… ä½¿ç”¨èˆ‡è¨“ç·´ç›¸åŒçš„æ–¹å¼è¨ˆç®— Dice
            metrics = calculate_metrics(output, mask, self.config['n_classes'])
            result['metrics'] = metrics
            
            print(f"   âœ… å¹³å‡ Dice: {metrics['mean_dice']:.4f}")
            if 'per_class_dice' in metrics:
                print(f"   ğŸ“Š é¡åˆ¥ Dice: {metrics['per_class_dice']}")
            
            # ğŸ” è¨ºæ–·ä¿¡æ¯
            print(f"   ğŸ” è¨ºæ–·:")
            print(f"      - è¼¸å‡ºå½¢ç‹€: {output.shape}")
            print(f"      - é æ¸¬ç‚ºå‰æ™¯çš„åƒç´ : {np.sum(prediction_binary == 1)} / {prediction_binary.size}")
            print(f"      - çœŸå¯¦å‰æ™¯åƒç´ : {np.sum(mask.cpu().numpy() == 1)}")
        
        return result
    
    def infer_folder(self, images_folder, masks_folder=None, target_size=(64, 64, 64), 
                     save_results=True, output_dir=None):
        """
        å°æ•´å€‹æ–‡ä»¶å¤¾çš„æ¨£æœ¬é€²è¡Œæ¨ç†
        
        Args:
            images_folder: å½±åƒæ–‡ä»¶å¤¾è·¯å¾‘
            masks_folder: é®ç½©æ–‡ä»¶å¤¾è·¯å¾‘ï¼ˆå¯é¸ï¼‰
            target_size: ç›®æ¨™å°ºå¯¸
            save_results: æ˜¯å¦ä¿å­˜çµæœ
            output_dir: çµæœä¿å­˜ç›®éŒ„
            
        Returns:
            list: æ‰€æœ‰çµæœ
        """
        images_path = Path(images_folder)
        masks_path = Path(masks_folder) if masks_folder else None
        
        # ç²å–æ‰€æœ‰å½±åƒæ–‡ä»¶
        image_files = sorted(images_path.glob('*.nii.gz')) + sorted(images_path.glob('*.nii'))
        
        if not image_files:
            print(f"âŒ åœ¨ {images_folder} ä¸­æ‰¾ä¸åˆ°å½±åƒæ–‡ä»¶")
            return []
        
        print(f"ğŸ“ æ‰¾åˆ° {len(image_files)} å€‹æ¨£æœ¬")
        
        all_results = []
        all_dice_scores = []
        
        # ä½¿ç”¨é€²åº¦æ¢ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        iterator = tqdm(image_files, desc="æ¨ç†é€²åº¦") if TQDM_AVAILABLE else image_files
        
        for image_file in iterator:
            # æŸ¥æ‰¾å°æ‡‰çš„é®ç½©
            mask_file = None
            if masks_path and masks_path.exists():
                mask_file = masks_path / image_file.name
                if not mask_file.exists():
                    mask_file = None
            
            # æ¨ç†
            result = self.infer_single_sample(str(image_file), mask_file, target_size)
            
            if result:
                all_results.append(result)
                if 'metrics' in result:
                    all_dice_scores.append(result['metrics']['mean_dice'])
        
        # ç”Ÿæˆæ‘˜è¦
        if all_dice_scores:
            summary = {
                'total_samples': len(all_results),
                'avg_dice': float(np.mean(all_dice_scores)),
                'std_dice': float(np.std(all_dice_scores)),
                'min_dice': float(np.min(all_dice_scores)),
                'max_dice': float(np.max(all_dice_scores)),
                'timestamp': datetime.now().isoformat()
            }
            
            print("\n" + "=" * 60)
            print("ğŸ“Š æ¨ç†æ‘˜è¦")
            print("=" * 60)
            print(f"ç¸½æ¨£æœ¬æ•¸: {summary['total_samples']}")
            print(f"å¹³å‡ Dice: {summary['avg_dice']:.6f}")
            print(f"æ¨™æº–å·®: {summary['std_dice']:.6f}")
            print(f"æœ€å° Dice: {summary['min_dice']:.6f}")
            print(f"æœ€å¤§ Dice: {summary['max_dice']:.6f}")
            print("=" * 60)
            
            # ä¿å­˜çµæœ
            if save_results:
                self._save_results(all_results, summary, output_dir)
        
        return all_results, summary if all_dice_scores else None
    
    def _save_results(self, results, summary, output_dir=None):
        """ä¿å­˜æ¨ç†çµæœ"""
        if output_dir is None:
            output_dir = Path('./inference_results')
        else:
            output_dir = Path(output_dir)
        
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # ä¿å­˜æ‘˜è¦ç‚º JSON
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        summary_file = output_dir / f"inference_summary_{timestamp}.json"
        
        summary_data = {
            'model_config': self.config,
            'summary': summary,
            'method': 'argmax',  # âœ… æ¨™è¨˜ä½¿ç”¨çš„æ–¹æ³•
            'results': [
                {
                    'image_path': r['image_path'],
                    'metrics': r.get('metrics', {}),
                    'predicted_foreground_pixels': int(np.sum(r.get('prediction', 0) == 1))
                }
                for r in results
            ]
        }
        
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump(summary_data, f, ensure_ascii=False, indent=2)
        
        print(f"\nâœ… çµæœå·²ä¿å­˜åˆ°: {summary_file}")


def main():
    """ä¸»æ¨ç†å‡½æ•¸"""
    parser = argparse.ArgumentParser(
        description='ä½¿ç”¨è¨“ç·´å¥½çš„æ¨¡å‹é€²è¡Œæ¨ç†ï¼ˆä½¿ç”¨ Argmaxï¼‰',
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )
    
    # å¿…éœ€åƒæ•¸
    parser.add_argument('--model_path', type=str, required=True,
                        help='è¨“ç·´å¥½çš„æ¨¡å‹æ¬Šé‡è·¯å¾‘')
    parser.add_argument('--images_dir', type=str, required=True,
                        help='æ¸¬è©¦å½±åƒæ‰€åœ¨çš„æ–‡ä»¶å¤¾')
    
    # å¯é¸åƒæ•¸
    parser.add_argument('--masks_dir', type=str, default=None,
                        help='æ¸¬è©¦é®ç½©æ‰€åœ¨çš„æ–‡ä»¶å¤¾ï¼ˆå¯é¸ï¼Œç”¨æ–¼è¨ˆç®—æŒ‡æ¨™ï¼‰')
    parser.add_argument('--target_size', type=int, nargs=3, default=(64, 64, 64),
                        help='ç›®æ¨™å½±åƒå°ºå¯¸ (D H W)')
    parser.add_argument('--device', type=str, default='auto',
                        choices=['auto', 'cuda', 'cpu'],
                        help='è¨ˆç®—è¨­å‚™')
    parser.add_argument('--output_dir', type=str, default='./inference_results',
                        help='çµæœä¿å­˜ç›®éŒ„')
    parser.add_argument('--no_save', action='store_true',
                        help='ä¸ä¿å­˜çµæœ')
    
    # æ¨¡å‹é…ç½®åƒæ•¸
    parser.add_argument('--n_channels', type=int, default=1,
                        help='è¼¸å…¥é€šé“æ•¸')
    parser.add_argument('--n_classes', type=int, default=2,
                        help='è¼¸å‡ºé¡åˆ¥æ•¸')
    parser.add_argument('--base_channels', type=int, default=32,
                        help='åŸºç¤é€šé“æ•¸')
    parser.add_argument('--num_groups', type=int, default=8,
                        help='GroupNorm çµ„æ•¸')
    parser.add_argument('--bilinear', action='store_true',
                        help='ä½¿ç”¨é›™ç·šæ€§ä¸Šæ¡æ¨£')
    
    # resampling åƒæ•¸
    parser.add_argument('--spacing', type=float, nargs=3, default=None,
                        help='åŸå§‹è³‡æ–™çš„ spacing (z y x)ï¼Œä¾‹å¦‚ 3.0 1.0 1.0')
    parser.add_argument('--force_separate_z', type=int, default=None,
                        help='å¼·åˆ¶æ˜¯å¦åˆ†é›¢ z è»¸è™•ç† (0=False, 1=True, None=auto)')
    
    args = parser.parse_args()
    
    # æº–å‚™é…ç½®
    config = {
        'n_channels': args.n_channels,
        'n_classes': args.n_classes,
        'base_channels': args.base_channels,
        'num_groups': args.num_groups,
        'bilinear': args.bilinear
    }
    
    # é©—è­‰è·¯å¾‘
    model_path = Path(args.model_path)
    images_dir = Path(args.images_dir)
    
    if not model_path.exists():
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        return
    
    if not images_dir.exists():
        print(f"âŒ å½±åƒæ–‡ä»¶å¤¾ä¸å­˜åœ¨: {images_dir}")
        return
    
    masks_dir = Path(args.masks_dir) if args.masks_dir else None
    if masks_dir and not masks_dir.exists():
        print(f"âš ï¸  é®ç½©æ–‡ä»¶å¤¾ä¸å­˜åœ¨: {masks_dir}ï¼Œå°‡ä¸è¨ˆç®—æŒ‡æ¨™")
        masks_dir = None
    
    # è™•ç† spacing
    spacing = args.spacing if args.spacing else None
    force_separate_z = None
    if args.force_separate_z is not None:
        force_separate_z = bool(args.force_separate_z)
    
    print("\nğŸš€ é–‹å§‹æ¨ç†ï¼ˆä½¿ç”¨ Argmaxï¼‰...")
    print("=" * 60)
    
    # åˆå§‹åŒ–æ¨ç†å™¨
    inferencer = ModelInference(
        model_path=str(model_path),
        config=config,
        device=args.device,
        spacing=spacing,
        force_separate_z=force_separate_z
    )
    
    # åŸ·è¡Œæ¨ç†
    results, summary = inferencer.infer_folder(
        images_folder=str(images_dir),
        masks_folder=str(masks_dir) if masks_dir else None,
        target_size=tuple(args.target_size),
        save_results=not args.no_save,
        output_dir=args.output_dir
    )
    
    print("\nâœ… æ¨ç†å®Œæˆï¼")


if __name__ == '__main__':
    main()